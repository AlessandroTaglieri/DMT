#HOMEWORK 2 - DMT. PART-1 RECOMMENDATION SYSTEM EVALUATION

#GROUP MEMBERS: Alessandro Taglieri, Guglielmo Lato

#IMPORT LIBRARIES
import networkx as nx
import pprint as pp
import csv
import pandas as pd
from pathlib import Path
import os
def compute_good_local_community(graph, seed_node_id, alpha, expo):
    #
    # Creation of the teleporting probability distribution for the selected node...
    map_teleporting_probability_distribution__node_id__probability = {}
    for node_id in graph:
        map_teleporting_probability_distribution__node_id__probability[node_id] = 0.
    map_teleporting_probability_distribution__node_id__probability[seed_node_id] = 1.
    #
    # Computation of the PageRank vector.
    map__node_id__node_pagerank_value = nx.pagerank(graph, alpha=alpha,
                                                    personalization=map_teleporting_probability_distribution__node_id__probability)
    #
    # Put all nodes in a list and sort the list in descending order of the â€œnormalized_scoreâ€.
    sorted_list__node_id__normalized_score = [(node_id, score / graph.degree[node_id]**expo)
                                              for node_id, score in map__node_id__node_pagerank_value.items()]
    sorted_list__node_id__normalized_score.sort(key=lambda x: (-x[1], x[0]))
    #
    # LET'S SWEEP!
    index_representing_the_set_of_node_ids_with_maximum_conductance = -1
    min_conductance_value = float("+inf")
    set__node_ids_in_the_candidate_community = set()
    set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes = set(graph.nodes())
    for sweep_index in range(0, len(sorted_list__node_id__normalized_score) - 1):
        #
        # Creation of the set of nodes representing the candidate community and
        # its complement to the entire set of nodes in the graph.
        current_node_id = sorted_list__node_id__normalized_score[sweep_index][0]
        set__node_ids_in_the_candidate_community.add(current_node_id)
        set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes.remove(current_node_id)
        #
        # Evaluation of the quality of the candidate community according to its conductance value.
        conductance_value = nx.algorithms.cuts.conductance(graph,
                                                           set__node_ids_in_the_candidate_community,
                                                           set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes)
        #
        # Discard local communities with conductance 0 or 1.
        if conductance_value == 0. or conductance_value == 1.:
            continue
        #
        # Update the values of variables representing the best solution generated so far.
        if conductance_value < min_conductance_value:
            min_conductance_value = conductance_value
            index_representing_the_set_of_node_ids_with_maximum_conductance = sweep_index
    #
    # Creation of the set of nodes representing the best local community generated by the sweeping procedure.
    set__node_ids_with_minimum_conductance = set([node_id for node_id, normalized_score in
                                                  sorted_list__node_id__normalized_score[
                                                  :index_representing_the_set_of_node_ids_with_maximum_conductance + 1]])
    #
    return set__node_ids_with_minimum_conductance, min_conductance_value



def create_graph_from_file(filename: str):
    graph = nx.Graph()
    tsv_file = open(filename)
    read_tsv = csv.reader(tsv_file, delimiter="\t")
    for row in read_tsv:
        graph.add_edge(row[0],row[1])
    tsv_file.close()
    return graph

def searchString(lista:[str],stringa:str):
    result=0
    for name in lista:
        if(stringa in name):
            result+=1
    return result

books = ["book_1.tsv","book_2.tsv","book_3.tsv","book_4.tsv"]
characters = ['Daenerys-Targaryen','Jon-Snow','Samwell-Tarly','Tyrion-Lannister']
alphas = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]
exps = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
df = pd.DataFrame(columns=['Book','Character','Dumping_factor','Exponent','Condunctance','Baratheon','Lannister','Stark','Targaryen','Total'])

# path of dataset file
path=Path(os.getcwd())
file_path=str(path.parent.parent)+"/part_2/dataset/"

for book in books:
    G = create_graph_from_file(file_path+book)
    for character in characters:
        min_conductance = float("+inf")
        min_community = []
        min_alpha = 0
        min_exp = 0
        for alpha in alphas[::-1]:
            for exp in exps:
                community, conductance = compute_good_local_community(G,character,alpha,exp)
                if (conductance not in [0., 1.]) & (conductance < min_conductance):
                    min_conductance = conductance
                    min_community = community
                    min_alpha = alpha
                    min_exp = exp
        row = [book,
               character,
               min_alpha,
               min_exp,
               min_conductance,
               searchString(min_community,'Baratheon'),
               searchString(min_community,'Lannister'),
               searchString(min_community,'Stark'),
               searchString(min_community,'Targaryen'),
               len(min_community)]
        df.loc[len(df)] = row
        #print(row)

#print(df)
file_path_tsv=str(path.parent.parent)+"/part_2/output.tsv"
df.to_csv(file_path_tsv,sep ="\t")